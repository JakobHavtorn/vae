{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"import os\n\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.utils.data\n\nfrom torch import nn, optim\nfrom torch.autograd import Variable\nfrom torch.nn import functional as F\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import save_image"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"os.environ['CUDA_VISIBLE_DEVICES'] = '3'\nSEED = 1\nBATCH_SIZE = 64\nLOG_INTERVAL = 10\nEPOCHS = 10\nN_SAMPLES = 10\nLATENT_DIM = 20\nNUM_WORKERS = 2"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if cuda else \"cpu\")\ntorch.manual_seed(SEED)\nif cuda:\n    torch.cuda.manual_seed(SEED)"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"kwargs = {'num_workers': NUM_WORKERS, 'pin_memory': True} if cuda else {}"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"# Download or load downloaded MNIST dataset\ntrain_dataset = datasets.MNIST(\n    './',\n    train=True,\n    download=True,\n    transform=transforms.Compose([\n        #transforms.RandomRotation(30),\n        transforms.ToTensor(),\n        #transforms.Normalize((0,), (255,)),\n    ])\n    \n)\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    **kwargs\n)\ntest_dataset = datasets.MNIST(\n    './',\n    train=False,\n    transform=transforms.Compose([\n        transforms.ToTensor(),\n        #transforms.Normalize((0,), (255,)),\n    ])\n)\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    **kwargs\n)"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"x, y = next(iter(train_loader))\nplt.imshow(x[0][0])"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"class Encoder(nn.Module):\n    def __init__(self, latent_dim):\n        super().__init__()\n        self.latent_dim = latent_dim\n        # Convolutions with same padding\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(4, 4), padding=(15, 15), stride=2)\n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(4, 4), padding=(15, 15), stride=2)\n        self.fc_mu = nn.Linear(in_features=16 * 28 * 28, out_features=latent_dim)\n        self.fc_logvar = nn.Linear(in_features=16 * 28 * 28, out_features=latent_dim)\n        self.relu = nn.ReLU()\n        \n    def forward(self, x):\n        x = x.view(-1, 1, 28, 28)\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = x.view(-1, 16 * 28 * 28)\n        mu_z = self.fc_mu(x)\n        logvar_z = self.fc_logvar(x)\n        return mu_z, logvar_z"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"class Decoder(nn.Module):\n    def __init__(self, latent_dim):\n        super().__init__()\n        self.latent_dim = latent_dim\n        # Convolutions with same padding\n        self.fc1 = nn.Linear(in_features=latent_dim, out_features=128 * 7 * 7)\n        self.conv_t1 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, padding=1, stride=2)\n        self.conv_t2 = nn.ConvTranspose2d(in_channels=64, out_channels=1, kernel_size=4, padding=1, stride=2)\n        self.relu = nn.ReLU()\n        \n    def forward(self, z: Variable) -> Variable:\n        x = self.relu(self.fc1(z))\n        x = x.view(-1, 128, 7, 7)\n        x = self.relu(self.conv_t1(x))\n        x = torch.sigmoid(self.conv_t2(x))\n        return x"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":"class VAE(nn.Module):\n    def __init__(self, encoder, decoder, n_samples, latent_dim):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.n_samples = n_samples\n        self.latent_dim = latent_dim\n\n    def reparameterize(self, mu: Variable, logvar: Variable) -> Variable:\n        if self.training:\n            z_samples = []\n            for _ in range(self.n_samples):\n                # Multiply log variance with 0.5, then in-place exponent\n                # yielding the standard deviation\n                std = logvar.mul(0.5).exp()  # type: Variable\n                # eps = Variable(std.data.new(std.size()).normal_())\n                # Sample a noise term from a standard normal\n                eps = torch.randn_like(std)\n                z_samples.append(eps.mul(std).add_(mu))\n            return z_samples\n        # During inference, we simply spit out the mean of the\n        # learned distribution for the current input.  We could\n        # use a random sample from the distribution, but mu of\n        # course has the highest probability.\n        return mu\n    \n    def sample(self, n_samples=1):\n        z = Variable(torch.randn(n_samples, self.latent_dim)).to(device)\n        return self.decoder.forward(z).cpu()\n\n    def forward(self, x: Variable) -> (Variable, Variable, Variable):\n        mu, logvar = self.encoder.forward(x)\n        z = self.reparameterize(mu, logvar)\n        if self.training:\n            return [self.decoder.forward(z) for z in z], mu, logvar\n        return self.decoder.forward(z), mu, logvar"},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-10-11T23:59:05.798771Z","start_time":"2019-10-11T23:59:05.787981Z"}},"outputs":[],"source":"class KLDivergenceLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, mu, logvar):\n        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / mu.shape[0]\n\n\nclass ReconstructionLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, xhat_samples, x):\n        if self.training:\n            BCE = 0\n            for xhat in xhat_samples:\n                BCE += F.binary_cross_entropy(xhat.view(-1, 784), x.view(-1, 784), reduction='sum')\n            return BCE / len(xhat_samples) / BATCH_SIZE\n        BCE = F.binary_cross_entropy(xhat_samples[0].view(-1, 784), x.view(-1, 784), reduction='sum')"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"# Training"},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-10-11T23:59:10.083170Z","start_time":"2019-10-11T23:59:10.070459Z"}},"outputs":[],"source":"# Setup\nencoder = Encoder(LATENT_DIM)\ndecoder = Decoder(LATENT_DIM)\nvae = VAE(encoder, decoder, N_SAMPLES, LATENT_DIM)\nvae.to(device)\n\noptimizer = optim.Adam(vae.parameters(), lr=1e-4)\n\nkl_divergence_loss = KLDivergenceLoss()\nrecon_loss = ReconstructionLoss()"},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-10-11T23:57:36.934668Z","start_time":"2019-10-11T23:57:36.921056Z"}},"outputs":[],"source":"# Training loop\ndef train(epoch):\n    vae.train()\n    train_loss = 0\n    # in the case of MNIST, len(train_loader.dataset) is 60000\n    # each `data` is of BATCH_SIZE samples and has shape [128, 1, 28, 28]\n    for batch_idx, (x, _) in enumerate(train_loader):\n        x = Variable(x)\n        x = x.to(device)\n\n        optimizer.zero_grad()\n\n        xhat, mu, logvar = vae.forward(x)\n        \n        rc_loss = recon_loss(xhat, x)\n        kl_loss =  kl_divergence_loss(mu, logvar)\n        loss = rc_loss + kl_loss\n\n        loss.backward()\n\n        optimizer.step()\n        \n        train_loss += loss.item()\n\n        if batch_idx % LOG_INTERVAL == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tRCLoss: {:.6f}, KLLoss: {:.6f}'.format(epoch, batch_idx * len(x), len(train_loader.dataset),\n                       100. * batch_idx / len(train_loader),\n                       rc_loss.item(), kl_loss.item()))\n\n    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n\n    \ndef test(epoch):\n    model.eval()\n    test_loss = 0\n\n    # each data is of BATCH_SIZE (default 128) samples\n    for i, (data, _) in enumerate(test_loader):\n        data = data.to(device)\n\n        # we're only going to infer, so no autograd at all required: volatile=True\n        data = Variable(data, volatile=True)\n        xhat, mu, logvar = vae(data)\n        \n        rc_loss = recon_loss(xhat, x)\n        kl_loss =  kl_divergence_loss(mu, logvar)\n        loss = rc_loss + kl_loss\n\n        if i == 0:\n            n = min(data.size(0), 8)\n            # for the first 128 batch of the epoch, show the first 8 input digits\n            # with right below them the reconstructed output digits\n            comparison = torch.cat([data[:n], xhat.view(BATCH_SIZE, 1, 28, 28)[:n]])\n            save_image(comparison.data.cpu(), './mnist/reconstruction_' + str(epoch) + '.png', nrow=n)\n\n    test_loss /= len(test_loader.dataset)\n    print('====> Test set loss: {:.4f}'.format(loss))"},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-10-11T23:57:46.724976Z","start_time":"2019-10-11T23:57:37.650073Z"}},"outputs":[],"source":"for epoch in range(1, EPOCHS + 1):\n    train(epoch)\n    test(epoch)"},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-10-11T23:59:48.062056Z","start_time":"2019-10-11T23:59:47.911335Z"}},"outputs":[],"source":"xgen = vae.sample()\nxgen = xgen.detach().numpy()[0, 0, ...]\nplt.imshow(xgen)\nxgen.max(), xgen.min(), xgen.mean()"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["# Tests"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-10-11T23:45:22.521916Z","start_time":"2019-10-11T23:45:22.341708Z"}},"outputs":[],"source":"x, y = next(iter(train_loader))\nprint(x.shape)\nprint(x.max())\nplt.imshow(x[0][0])"},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-10-11T23:45:23.033441Z","start_time":"2019-10-11T23:45:23.028819Z"}},"outputs":[],"source":"#encoder = Encoder(LATENT_DIM)\n#decoder = Decoder(LATENT_DIM)\n#vae = VAE(encoder, decoder, N_SAMPLES)"},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-10-11T23:45:23.541621Z","start_time":"2019-10-11T23:45:23.532960Z"}},"outputs":[],"source":"mu, logvar = encoder.forward(x[0, ...])\nmu, logvar.exp()"},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-10-11T23:45:24.211424Z","start_time":"2019-10-11T23:45:24.039086Z"}},"outputs":[],"source":"xhat = decoder.forward(mu)\nplt.imshow(xhat.detach().numpy()[0][0])"},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-10-11T23:45:24.851413Z","start_time":"2019-10-11T23:45:24.440866Z"}},"outputs":[],"source":"xhat, mu, logvar = vae.forward(x)\nplt.imshow(xhat[0].detach().numpy()[0][0])"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}